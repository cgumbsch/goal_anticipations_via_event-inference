{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import interaction_gym\n",
    "import numpy as np\n",
    "import event_inference as event\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_component_name(i):\n",
    "    if i == 0:\n",
    "        return 'start'\n",
    "    if i == 1:\n",
    "        return 'dynamics'\n",
    "    return 'end'\n",
    "\n",
    "def get_event_name(e_i):\n",
    "    if e_i == 0:\n",
    "        return 'still'\n",
    "    if e_i == 1:\n",
    "        return 'rand'\n",
    "    if e_i == 2:\n",
    "        return 'reach'\n",
    "    return 'transport'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventComponentDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for one event component. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, e_i, component_name):\n",
    "        \"\"\"\n",
    "        Creates the dataset for one component (component_name in ['start', 'dynamics', 'end']) and one event e_i \n",
    "        \"\"\"\n",
    "        event_name = get_event_name(e_i)\n",
    "        input_path = 'Data/input_' + event_name + '_' + component_name + '.npy'\n",
    "        target_path = 'Data/target_' + event_name + '_' + component_name + '.npy'\n",
    "        self.input_data = np.load(input_path)\n",
    "        self.target_data = np.load(target_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.input_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.target_data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_train = 1280\n",
    "batch_size = 128\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = event.EventInferenceSystem(epsilon_start=0.01, epsilon_dynamics=0.001, epsilon_end=0.001,\n",
    "                                   no_transition_prior=0.9, dim_observation=18, num_policies=3, \n",
    "                                   num_models=4, r_seed=seed, sampling_rate=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data for every event $e_i$ and every subcomponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = [[], [], [], []]\n",
    "for e_i in range(4):\n",
    "    for c in range(3):\n",
    "        dataset = EventComponentDataset(e_i, index_to_component_name(c))\n",
    "        \n",
    "        num_data = len(dataset)\n",
    "        num_data_ignore = num_data - num_data_train\n",
    "        \n",
    "        train_dataset, _ = torch.utils.data.random_split(dataset, [num_data_train, num_data_ignore],\n",
    "                                                         generator=torch.Generator().manual_seed(seed))\n",
    "        \n",
    "        dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        dataloaders[e_i].append(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the system using batches\n",
    "\n",
    "We train our model for 500 epochs. In every epoch every component of every event is updated based on 1280 datapoints that are randomly assigned to batches of size 128. We print the mean negative log likelihood during training every 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(501):\n",
    "    # Iterate over epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"--------------- EPOCH \", epoch, \"---------------\")\n",
    "    for e_i in range(4):\n",
    "        # Iterate over events\n",
    "        \n",
    "        for c in range(3):\n",
    "            # Iterate over components (start, dynamics, end)\n",
    "            \n",
    "            dataloader_ei_c = dataloaders[e_i][c]\n",
    "            \n",
    "            nll_sum = 0.0\n",
    "            \n",
    "            for inps, targets in dataloader_ei_c:\n",
    "                # Iterate through dataset\n",
    "                nll = model.update_batch(inps, targets, e_i, index_to_component_name(c))\n",
    "                nll_sum += nll\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Event \", get_event_name(e_i), \" and \", index_to_component_name(c), \"-component: NLL of \", nll_sum/10)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the system:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = interaction_gym.InteractionEventGym(sensory_noise_base=1.0, sensory_noise_focus=0.01, randomize_colors = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below runs the testing phase 3 times with event and policy inference of the system.\n",
    "Here the agent is a hand. We print the inferred events and policy chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for episodes in range(3):\n",
    "    print(\"--------------- EPISODE \", episodes, \"---------------\")\n",
    "    # Reset environment to new event sequence\n",
    "    observation = env.reset_to_grasping(claw=False) # claw=False for hand-agent\n",
    "    \n",
    "    # Sample one-hot-encoding of policy pi(0)\n",
    "    policy_t = np.array([0.0, 0.0, 0.0])\n",
    "    policy_t[2] = 1.0\n",
    "    for t in range(3000):\n",
    "        #Rendering if desired:\n",
    "        env.render() #store_video=True, video_identifier=0)\n",
    "        \n",
    "        # Perform pi(t) and receive new observation o(t)\n",
    "        observation, reward, done, info = env.step(policy_t)\n",
    "        \n",
    "        # Update the event probabilities, event schemata, and infer next policy\n",
    "        policy_t, P_ei = model.step(o_t=observation, pi_t=policy_t, training=False, done=done, e_i=info)\n",
    "        print(\"P_ei[t=\", t, \"] = \", P_ei, \" with real event \", info)\n",
    "        \n",
    "        # Next sequence when event sequence is over\n",
    "        if done:\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
